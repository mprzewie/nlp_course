{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab4 - Multiword expressions identification and extraction\n",
    "\n",
    "The task shows two simple methods useful for identifying multiword expressions (MWE) in corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import string\n",
    "from typing import Tuple, Dict\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute **bigram** counts in the corpora, ignoring bigrams which contain at least one token that is not a word\n",
    "   (it contains characters other than letters). The text has to be properly normalized before the counts are computed:\n",
    "   it should be downcased and all punctuation should be removed. Given the sentence: \"The quick borwn fox jumps over the\n",
    "   lazy dog\", the bigram counts are as follows:\n",
    "   1. \"the quick\": 1\n",
    "   1. \"quick brown\": 1\n",
    "   1. \"brown fox\": 1\n",
    "   1. etc.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "def lemmatize(word: str) -> str:\n",
    "    analysis = es.indices.analyze(\n",
    "        \"przewie\",\n",
    "        {\n",
    "            \"tokenizer\": \"standard\",\n",
    "             \"filter\": [\"kodeks_synonym\", \"lowercase\", \"morfologik_stem\"],\n",
    "            \"text\": word\n",
    "        }\n",
    "    )\n",
    "    return analysis[\"tokens\"][0][\"token\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(text: str):\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    return [\n",
    "        ngram\n",
    "        for ngram in zip(words[:-1], words[1:]) \n",
    "        if all(w.isalpha() for w in ngram)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1180it [00:17, 66.78it/s]\n"
     ]
    }
   ],
   "source": [
    "bigrams = {}\n",
    "\n",
    "for file in tqdm(Path(\"../data/\").glob(\"*.txt\")):\n",
    "    with file.open() as f:\n",
    "        text = f.read()\n",
    "    bgrams = get_bigrams(text)\n",
    "    for bg in bgrams:\n",
    "        bigrams[bg] = bigrams.get(bg, 0) + 1\n",
    "bigrams;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 185086/640189 [09:08<28:23, 267.17it/s]"
     ]
    }
   ],
   "source": [
    "lem_cache = {}\n",
    "bigrams_non_lemmatized = bigrams\n",
    "bigrams_lemmatized = {}\n",
    "\n",
    "for bgram, count in tqdm(bigrams_non_lemmatized.items()):\n",
    "    for w in bgram:\n",
    "        lem_cache[w] = lem_cache.get(w, lemmatize(w))\n",
    "    lem_bgram = tuple(lem_cache[w] for w in bgram)\n",
    "    bigrams_lemmatized[lem_bgram] = bigrams_lemmatized.get(lem_bgram, 0) + count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = bigrams_lemmatized\n",
    "\n",
    "words = {}\n",
    "\n",
    "for ngram, cnt in bigrams.items():\n",
    "    for w in ngram:\n",
    "        words[w] = words.get(w, 0) + cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use [pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) to compute the measure \n",
    "   for all pairs of words. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(ngram: Tuple[str, ...], ngrams: Dict[Tuple[str, ...], int], words: Dict[str, int]):\n",
    "    return np.log((ngrams[ngram] * (len(words) ** len(ngram))) / (np.prod([words[w] for w in ngram]) * ngrams[ngram]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrams_pmis = {\n",
    "    ngram: pmi(ngram, bigrams, words)\n",
    "    for ngram in bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Sort the word pairs according to that measure in the descending order and display 30 top results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('bordetella', 'pertussis'), 19.83596399737316),\n",
       " (('campylobacter', 'jejuni'), 19.83596399737316),\n",
       " (('corynebacterium', 'diphtheriae'), 19.83596399737316),\n",
       " (('coxiella', 'burneti'), 19.83596399737316),\n",
       " (('francisella', 'tularensis'), 19.83596399737316),\n",
       " (('helicobacter', 'pylori'), 19.83596399737316),\n",
       " (('legionella', 'pneumophila'), 19.83596399737316),\n",
       " (('listeria', 'monocytogenes'), 19.83596399737316),\n",
       " (('toxoplasma', 'gondii'), 19.83596399737316),\n",
       " (('vibrio', 'cholerae'), 19.83596399737316),\n",
       " (('zołzy', 'strangles'), 19.83596399737316),\n",
       " (('waroza', 'varroosis'), 19.83596399737316),\n",
       " (('argyreia', 'nervosa'), 19.83596399737316),\n",
       " (('dekstromoramid', 'palfium'), 19.83596399737316),\n",
       " (('pirolidyna', 'lewotenacylomorfan'), 19.83596399737316),\n",
       " (('mppp', 'propionian'), 19.83596399737316),\n",
       " (('butylomorfolina', 'racemorfan'), 19.83596399737316),\n",
       " (('brolamfetamina', 'dob'), 19.83596399737316),\n",
       " (('netylomda', 'mdea'), 19.83596399737316),\n",
       " (('etycyklidyna', 'pce'), 19.83596399737316),\n",
       " (('psylocybina', 'diwodorofosforan'), 19.83596399737316),\n",
       " (('tenamfetamina', 'mda'), 19.83596399737316),\n",
       " (('tenocyklidyna', 'tcp'), 19.83596399737316),\n",
       " (('benzol', 'benzen'), 19.83596399737316),\n",
       " (('toluol', 'toluen'), 19.83596399737316),\n",
       " (('tornister', 'nieskórzany'), 19.83596399737316),\n",
       " (('reduktor', 'membranowy'), 19.83596399737316),\n",
       " (('paź', 'dziernika'), 19.83596399737316),\n",
       " (('izocyjanian', 'tiocyjaniany'), 19.83596399737316),\n",
       " (('nm', 'nanometr'), 19.83596399737316)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bgrams_pmis.items(), key=lambda it: it[1])[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use [log likelihood ratio](http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html) (LLR) to compute the measure for all pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k: np.ndarray):\n",
    "    N = k.sum()\n",
    "    return (\n",
    "        (k / N) * np.log(k / N + 1e-7)\n",
    "    ).sum()\n",
    "\n",
    "def LLR(k: np.ndarray):\n",
    "    return (2 * k.sum()) * (\n",
    "        H(k) - \n",
    "        H(k.sum(axis=0)) - \n",
    "        H(k.sum(axis=1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ngrams = np.sum(list(bigrams.values()))\n",
    "\n",
    "def incidence(bigram: Tuple[str, str], ngrams: Dict[Tuple[str, str], int], words: Dict[str, int]) -> np.ndarray:\n",
    "    w1, w2 = bigram\n",
    "    w1_w2 = ngrams.get((w1, w2), 0) + ngrams.get((w2, w1), 0)\n",
    "    w1_not_w2 = words[w1] - w1_w2\n",
    "    w2_not_w1 = words[w2] - w1_w2\n",
    "    not_w1_not_w2 = all_ngrams - w1_not_w2 - w1_not_w2 - w1_w2\n",
    "    return np.array([\n",
    "        [w1_w2, w1_not_w2],\n",
    "        [w2_not_w1, not_w1_not_w2]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgrams_llrs = {\n",
    "    ngram: LLR(incidence(ngram, bigrams, words))\n",
    "    for ngram in bigrams\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Sort the word pairs according to that measure in the descending order and display 30 top results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('który', 'mowa'), 127655.40755779158),\n",
       " (('rok', 'numer'), 116966.1608559136),\n",
       " (('otrzymywać', 'brzmienie'), 98492.87630740176),\n",
       " (('w', 'w'), 93226.9629069246),\n",
       " (('który', 'o'), 76453.93116680977),\n",
       " (('o', 'który'), 75413.05010340967),\n",
       " (('mowa', 'w'), 56900.23849597701),\n",
       " (('artykuł', 'w'), 54975.43246118754),\n",
       " (('w', 'usta'), 54682.84690696392),\n",
       " (('w', 'mowa'), 47158.037762626955),\n",
       " (('w', 'artykuł'), 44970.31859297557),\n",
       " (('dodawać', 'się'), 44842.17020953167),\n",
       " (('minister', 'właściwy'), 44240.38882282183),\n",
       " (('właściwy', 'minister'), 44208.11556208072),\n",
       " (('się', 'dodawać'), 44008.17732058322),\n",
       " (('w', 'z'), 38182.57269139614),\n",
       " (('od', 'dzień'), 35969.86660991811),\n",
       " (('dzień', 'od'), 35905.660817134456),\n",
       " (('droga', 'rozporządzenie'), 35870.459722368025),\n",
       " (('w', 'o'), 34807.366777988296),\n",
       " (('rzeczpospolita', 'polski'), 33449.24891476344),\n",
       " (('polski', 'rzeczpospolita'), 33426.24342250982),\n",
       " (('z', 'w'), 32759.667551757277),\n",
       " (('w', 'do'), 31347.709514677845),\n",
       " (('o', 'w'), 29603.015442872387),\n",
       " (('w', 'i'), 28687.183862005495),\n",
       " (('dzień', 'z'), 27988.144046915964),\n",
       " (('stosować', 'się'), 27891.127103850267),\n",
       " (('się', 'stosować'), 27258.134158711895),\n",
       " (('w', 'na'), 26887.246438993894)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bgrams_llrs.items(), key=lambda it: it[1])[-30:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.653898383236346"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(bgrams_llrs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mprzewie/.anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log10\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(list(bgrams_llrs.values())), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tekst', 'ustawa'), 1080.3841803183445),\n",
       " (('przekazać', 'do'), 49.513085377699426),\n",
       " (('senat', 'zgodnie'), 78.52376330644368),\n",
       " (('zgodnie', 'z'), 9587.177018007249),\n",
       " (('z', 'artykuł'), 2929.5649062202356),\n",
       " (('regulamin', 'sejm'), 189.50052442735438),\n",
       " (('ustawa', 'z'), 15871.824974745477),\n",
       " (('z', 'dzień'), 26628.965035025678),\n",
       " (('rok', 'o'), 10952.604088016227),\n",
       " (('o', 'zmiana'), 1411.6456769333402),\n",
       " (('zmiana', 'ustawa'), 1848.5462588417122),\n",
       " (('ustawa', 'o'), 396.1449813747711),\n",
       " (('niektóry', 'emeryt'), 42.14453770827742),\n",
       " (('emeryt', 'rencista'), 353.87352322960174),\n",
       " (('rencista', 'i'), 119.38133402562629),\n",
       " (('i', 'osoba'), 1096.341813739303),\n",
       " (('osoba', 'pobierać'), 221.79628068305604),\n",
       " (('pobierać', 'świadczenie'), 130.65783933265737),\n",
       " (('świadczenie', 'przedemerytalny'), 1095.9965207901705),\n",
       " (('zasiłek', 'przedemerytalny'), 1030.7735920323034)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for (k, v) in bgrams_llrs.items() if v > 40][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Answer the following questions:\n",
    "   \n",
    "### Which measure works better for the problem?\n",
    "\n",
    "LLR, as it takes into account not only how often this combination of words occurs together as opposed to those words separately and how often it occurs as opposed to other combinations.\n",
    "\n",
    "### What would be needed, besides good measure, to build a dictionary of multiword expressions?\n",
    "\n",
    "A lot of computational power and memory. Also, a good lemmatizer.\n",
    "\n",
    "### Can you identify a certain threshold which clearly divides the *good* expressions from the *bad*?\n",
    "\n",
    "I'd go for the mean LLR, which is about 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "1. An n-gram is a sequence containing n words. A unigram is a sequence containing one word,\n",
    "   a bigram is a sequence containing two words, etc.\n",
    "1. Pointwise mutual information is used to identify correlated events. It's based on the assumption that the events\n",
    "   follow normal distribution and that there is a minimal number of occurrences of the words. These assumptions hold\n",
    "   only for a subset of words.\n",
    "1. Log likelihood ratio test doesn't have these assumption. This makes it better suited for the task.\n",
    "1. There is [LLR implementation](https://github.com/tdunning/python-llr) in Python, implemented by Ted Dunning - the\n",
    "   author of the important work [Accurate Methods for the Statistics of Surprise and\n",
    "   Coincidence](https://aclweb.org/anthology/J93-1003) which introduces LLR to NLP.\n",
    "1. The methods presented in this exercise can be also used for the identification of words belonging to a given domain\n",
    "   (e.g. law, biology, medicine).\n",
    "1. [SRI LM](http://www.speech.sri.com/projects/srilm/) is useful for computing the counts of n-grams.\n",
    "1. ElasticSearch has a [shingle token filter](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-shingle-tokenfilter.html) \n",
    "   which can be used to build the n-grams as well.\n",
    "1. More sophisticated algorithms for multiword expressions identification, such as \n",
    "   [AutoPhrase](https://github.com/shangjingbo1226/AutoPhrase) take into account more features including:\n",
    "   morphosyntactic tags, expression contexts, etc. and use data from e.g. Wikipedia, to automatically identify\n",
    "   high-quality multiword expressions and use them to train MWE classifiers.\n",
    "1. BTW \"multiword expressions\" is a mutliword expression itself ;-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
