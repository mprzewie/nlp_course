{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab3 - Levenshtein distance and spelling corrections\n",
    "\n",
    "The task introduces the Levenshtein distance - a measure that is useful in tasks such as approximate string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use ElasticSearch term vectors API to retrieve and store for each document the following data:\n",
    "   1. The terms (tokens) that are present in the document.\n",
    "   2. The number of times given term is present in the document.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aggregate the result to obtain one global **frequency list**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Filter the list to keep terms that contain only letters and have at least 2 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make a plot in a logarithmic scale:\n",
    "   1. X-axis should contain the **rank** of a term, meaning the first rank belongs to the term with the highest number of\n",
    "      occurrences; the terms with the same number of occurrences should be ordered by their name,\n",
    "   2. Y-axis should contain the **number of occurrences** of the term with given rank.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Download [polimorfologik.zip](https://github.com/morfologik/polimorfologik/releases/download/2.1/polimorfologik-2.1.zip) dictionary\n",
    "   and use it to find all words that do not appear in that dictionary.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Find 30 words with the highest ranks that do not belong to the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Find 30 words with 3 occurrences that do not belong to the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use Levenshtein distance and the frequency list, to determine the most probable correction of the words from the\n",
    "   second list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "1. Levenshtein distance (Edit distance) is a measure defined for any pair of strings. It is defined as the minimal\n",
    "   number of single character edits (insertions, deletions or substitutions) needed to transform one string to the\n",
    "   other. The measure is symmetric.\n",
    "1. The algorithm is usually implemented as a dynamic program, see [Wikipedia article](https://en.wikipedia.org/wiki/Levenshtein_distance) \n",
    "   for details.\n",
    "1. The distance may be used to fix an invalid word by inspecting in the growing order of the distance, the words\n",
    "   that are *n* edits away from the invalid word. If there are no words *n* edits away, the words *n+1* edits away \n",
    "   are inspected.\n",
    "1. The frequency list may be used to select the most popular word with given distance, if there are many candidate\n",
    "   corrections.\n",
    "1. Usually the correction algorithm does not use the edit distance directly, since it would require to compare the\n",
    "   invalid word with all words in the dictionary. The algorithms work in the opposite way - the generate candidate words\n",
    "   that are 1 or 2 edits away from the invalid word (cf. P. Norvigs [article](https://norvig.com/spell-correct.html) \n",
    "   for the details). A different approach is to use [Levenshtein automaton](https://norvig.com/spell-correct.html) for\n",
    "   finding the corrections effectively.\n",
    "1. ElasticSearch has a [fuzziness](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html)\n",
    "   parameter for finding approximate matches of a query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
