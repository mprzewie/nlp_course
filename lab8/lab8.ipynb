{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab8 - Text classification\n",
    "\n",
    "The task concentrates on content-based text the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import dataclasses as dc\n",
    "from typing import List\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as skm\n",
    "from fasttext import supervised as fasttext\n",
    "from flair.data import TaggedCorpus, Sentence\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "import torch\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dc.dataclass\n",
    "class Dataset:\n",
    "    X_train: List\n",
    "    y_train: List\n",
    "    X_val: List\n",
    "    y_val: List    \n",
    "    X_test: List\n",
    "    y_test: List\n",
    "        \n",
    "    def preprocess(self, fn):\n",
    "        return dc.replace(\n",
    "            self,\n",
    "            X_train = [fn(x) for x in self.X_train],\n",
    "            X_val = [fn(x) for x in self.X_val],\n",
    "            X_test = [fn(x) for x in self.X_test],\n",
    "         )\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.X_train + self.X_val + self.X_test\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.y_train + self.y_val + self.y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "1. Divide the set of bills into two exclusive sets:\n",
    "   1. the set of bills amending other bills (their title starts with `o zmianie ustawy`),\n",
    "   1. the set of bills not amending other bills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = Path(\"../data\").glob(\"*.txt\")\n",
    "bills = [f.open().read().replace(\"  \", \" \").lower() for f in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_changing_bill(text):\n",
    "    return \"o zmianie ustawy\" in text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 488)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives_raw = [b for b in bills if is_changing_bill(b)]\n",
    "negatives_raw = [b for b in bills if not is_changing_bill(b)]\n",
    "\n",
    "len(positives_raw), len(negatives_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Change the contents of the bill by removing the date of publication and the title (so the words `o zmianie ustawy`\n",
    "   are removed).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives, negatives = [[\"\".join(b.split(\"art. 1\")[1:]) for b in ds] for ds in [positives_raw, negatives_raw]]\n",
    "X_ = positives + negatives\n",
    "y_ = ([1] * len(positives)) + ([0] * len(negatives))\n",
    "\n",
    "X = [x for x in X_ if len(x) > 0]\n",
    "y = [y for (x, y) in zip(X_, y_) if len(x) > 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the sets of documents into the following groups by randomly selecting the documents:\n",
    "   1. 60% training\n",
    "   1. 20% validation\n",
    "   1. 20% testing\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5)\n",
    "\n",
    "original_ds = Dataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Do not change these groups during the following experiments.\n",
    "5. Prepare the following variants of the documents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   a. full text of the document\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   b. randomly selected 10% of the lines of the document\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenpercentlines(text):\n",
    "    lines = [l for l in text.split(\"\\n\") if l != \"\"]\n",
    "    return \"\\n\".join(np.random.choice(lines, (len(lines) // 10) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   c. randomly selected 10 lines of the document\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenlines(text):\n",
    "    lines = [l for l in text.split(\"\\n\") if l != \"\"]\n",
    "    return \" \".join(np.random.choice(lines, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   d. randomly selected 1 line of the document\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneline(text):\n",
    "    lines = [l for l in text.split(\"\\n\") if l != \"\"]\n",
    "    return \" \".join(np.random.choice(lines, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train the following classifiers on the documents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   a. SVM with TFâ€¢IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_svm(ds: Dataset):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer().fit(ds.X)),\n",
    "        ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "    ])\n",
    "    parameters = {\n",
    "        'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        \"clf__estimator__C\": [0.01, 0.1, 0.5, 1],\n",
    "        \"clf__estimator__class_weight\": ['balanced', None],\n",
    "    }\n",
    "    grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=12, verbose=10)\n",
    "    grid_search_tune.fit(ds.X_train, ds.y_train)\n",
    "    \n",
    "    return grid_search_tune.best_estimator_.predict(ds.X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_ds(ds: Dataset):\n",
    "    out = Path(\"/tmp\") / str(np.random.randn())\n",
    "    out.mkdir()\n",
    "    for d in [\"train\", \"val\", \"test\"]:\n",
    "        X_d, y_d = getattr(ds, f\"X_{d}\"), getattr(ds, f\"y_{d}\")\n",
    "        txt = \"\\n\".join([\n",
    "          f\"__label__{y} {x}\"  \n",
    "            for (x,y) in zip(X_d, y_d)\n",
    "        ])\n",
    "        with (out / d).open(\"w\") as f:\n",
    "            f.write(txt)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_supervised(ds: Dataset):\n",
    "    ds_path = fasttext_ds(original_ds.preprocess(oneline))\n",
    "    ft = fasttext(\n",
    "        str(ds_path / \"train\"), str(ds_path / \"model\"),\n",
    "        epoch=10, \n",
    "#         word_ngrams=2, #kills the kernel\n",
    "    )\n",
    "    return [int(y[0]) for y in ft.predict(ds.X_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Flair with Polish language model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flair_model(ds: Dataset):\n",
    "\n",
    "    data_folder = fasttext_ds(ds)\n",
    "    corpus: TaggedCorpus = NLPTaskDataFetcher.load_classification_corpus(\n",
    "        str(data_folder),\n",
    "        test_file='test',\n",
    "        dev_file='val',\n",
    "        train_file='train'\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3. make a list of word embeddings\n",
    "    word_embeddings = [\n",
    "        WordEmbeddings('pl'), \n",
    "        FlairEmbeddings('polish-forward'),\n",
    "       FlairEmbeddings('polish-backward')\n",
    "    ]\n",
    "        \n",
    "\n",
    "    # 4. initialize document embedding by passing list of word embeddings\n",
    "    # Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "    document_embeddings: DocumentLSTMEmbeddings = DocumentLSTMEmbeddings(\n",
    "        word_embeddings,\n",
    "        hidden_size=512,\n",
    "        reproject_words=True,\n",
    "        reproject_words_dimension=256,\n",
    "        )\n",
    "\n",
    "    # 5. create the text classifier\n",
    "    classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "\n",
    "    # 6. initialize the text classifier trainer\n",
    "    trainer = ModelTrainer(\n",
    "        classifier, \n",
    "        corpus, \n",
    "#         optimizer=torch.optim.Adam()\n",
    "    )\n",
    "\n",
    "    # 7. start the training\n",
    "    model_path =  str(data_folder / \"model\"/ \"best-model.pt\")\n",
    "    trainer.train( \n",
    "        model_path,\n",
    "        learning_rate=0.1,\n",
    "        mini_batch_size=32,\n",
    "        anneal_factor=0.5,\n",
    "        patience=5,\n",
    "        max_epochs=1,\n",
    "        monitor_train=False\n",
    "    )    \n",
    "    return [\n",
    "        y.labels[0]\n",
    "        for y in \n",
    "        trainer.model.predict([Sentence(x) for x in ds.X_val])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Report Precision, Recall and F1 for each variant of the experiment (12 variants altogether)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_gt, y_pred):\n",
    "    return {\n",
    "        fn.__name__: fn(y_gt, y_pred)\n",
    "        for fn in [\n",
    "            skm.accuracy_score,\n",
    "            skm.precision_score,\n",
    "            skm.recall_score,\n",
    "            skm.f1_score\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 22:21:58,214 Reading data from /tmp/0.8919283111595587\n",
      "2019-05-12 22:21:58,215 Train: /tmp/0.8919283111595587/train\n",
      "2019-05-12 22:21:58,217 Dev: /tmp/0.8919283111595587/val\n",
      "2019-05-12 22:21:58,218 Test: /tmp/0.8919283111595587/test\n",
      "2019-05-12 22:21:58,446 this function is deprecated, use smart_open.open instead\n",
      "2019-05-12 22:22:15,332 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-12 22:22:15,333 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-12 22:22:15,336 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mprzewie/.anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 22:22:17,974 epoch 1 - iter 0/21 - loss 0.02180532\n",
      "2019-05-12 22:22:23,465 epoch 1 - iter 2/21 - loss 0.02127855\n",
      "2019-05-12 22:22:28,253 epoch 1 - iter 4/21 - loss 0.02142913\n",
      "2019-05-12 22:22:33,335 epoch 1 - iter 6/21 - loss 0.02142570\n",
      "2019-05-12 22:22:38,547 epoch 1 - iter 8/21 - loss 0.02142534\n",
      "2019-05-12 22:22:42,854 epoch 1 - iter 10/21 - loss 0.02119910\n",
      "2019-05-12 22:22:48,316 epoch 1 - iter 12/21 - loss 0.02100137\n",
      "2019-05-12 22:22:53,847 epoch 1 - iter 14/21 - loss 0.02089274\n",
      "2019-05-12 22:22:58,177 epoch 1 - iter 16/21 - loss 0.02095952\n",
      "2019-05-12 22:23:02,833 epoch 1 - iter 18/21 - loss 0.02100788\n",
      "2019-05-12 22:23:07,041 epoch 1 - iter 20/21 - loss 0.02179562\n",
      "2019-05-12 22:23:07,063 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-12 22:23:07,065 EPOCH 1 done: loss 0.0218 - lr 0.1000 - bad epochs 0\n",
      "2019-05-12 22:23:22,328 DEV  : loss 0.02183958 - f-score 0.6179 - acc 0.4471\n",
      "2019-05-12 22:23:37,858 TEST : loss 0.02121993 - f-score 0.6111 - acc 0.4400\n",
      "2019-05-12 22:26:18,941 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-12 22:26:22,935 Testing using best model ...\n",
      "2019-05-12 22:26:23,387 loading file /tmp/0.8919283111595587/model/best-model.pt/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    ds_name: {\n",
    "        model_fn.__name__: metrics(ds.y_val, model_fn(ds))\n",
    "        for model_fn in [\n",
    "#             tfidf_svm,\n",
    "#             fasttext_supervised,\n",
    "            flair_model\n",
    "        ]\n",
    "    }\n",
    "    for (ds_name, ds) in {\n",
    "        fn.__name__: original_ds.preprocess(fn) \n",
    "        for fn in\n",
    "        [\n",
    "            oneline,\n",
    "#             tenlines, \n",
    "#             tenpercentlines, \n",
    "#             full_text, \n",
    "        ]\n",
    "    }.items()\n",
    "}\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "\n",
    "1. Application of SVM classifier with TFâ€¢IDF is described in \n",
    "   [David Batista](http://www.davidsbatista.net/blog/2017/04/01/document_classification/) blog post.\n",
    "1. [Fasttext](https://fasttext.cc/) is a popular basline classifier. Don't report the Precision/Recall/F1 provided by\n",
    "   Fasttext since they might be [wrong](https://github.com/facebookresearch/fastText/issues/261).\n",
    "1. [Flair](https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f) \n",
    "   is another library for text processing. Flair classification is based on a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
